{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-hoc REPP Analysis Pipeline\n",
    "\n",
    "This notebook performs post-hoc analysis of tapping data collected from psynet experiments using the REPP.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The pipeline processes participant audio recordings from tapping experiments and performs beat detection analysis to extract rhythmic patterns and onsets. It handles data preprocessing, stimulus information extraction, and generates visualization plots for each recording.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Data Loading**: Loads participant data from a specified base directory containing:\n",
    "   - `TapTrialMusic.csv`: Trial and stimulus metadata\n",
    "   - Audio recordings in participant-specific directories\n",
    "\n",
    "2. **Audio Processing**: \n",
    "   - Converts stereo recordings to mono\n",
    "   - Resamples audio to 44.1 kHz if needed\n",
    "   - Saves processed WAV files in PCM_16 format\n",
    "\n",
    "3. **Stimulus Information Extraction**:\n",
    "   - Extracts trial metadata from CSV files\n",
    "   - Saves stimulus information as JSON files for each recording\n",
    "\n",
    "4. **REPP Beat Detection**:\n",
    "   - Runs REPP analysis on each participant recording\n",
    "   - Configures detection parameters (extraction thresholds, window sizes)\n",
    "   - Generates beat detection plots and extracts onset times\n",
    "   - Displays visualization plots for each analyzed recording\n",
    "\n",
    "## Output\n",
    "\n",
    "For each participant, the pipeline generates:\n",
    "- Converted audio files (`.wav`)\n",
    "- Stimulus information files (`.json`)\n",
    "- Beat detection analysis plots (`.png`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import json\n",
    "from importlib import reload\n",
    "from custom_config import sms_tapping\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from post_repp_pipeline import load_stim_info_from_csv\n",
    "\n",
    "from repp_beatfinding.beat_detection import (\n",
    "    do_beat_detection_analysis,\n",
    ") \n",
    "from repp.config import ConfigUpdater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parent directory path for Assets dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure paths\n",
    "base_dir = r\"D:\\pyspace\\Djembe\\psynet\\data_2025\\November-2025\\mali-group1-nov9\"     # Set base directory here\n",
    "output_dir = r\"output\"\n",
    "\n",
    "TapTrialMusic_path = os.path.join(base_dir, \"data\", \"TapTrialMusic.csv\")\n",
    "TapTrialMusic_df = pd.read_csv(TapTrialMusic_path)\n",
    "\n",
    "print(\"Sub-directories of assets\", os.listdir(os.path.join(base_dir, \"assets\")))\n",
    "print(\"Participant Ids:\", TapTrialMusic_df['participant_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose sub dir and participant id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_sub_dir = \"Task 1\"\n",
    "choose_participant_id = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_participant_dir = os.path.join(output_dir, f\"participant_{choose_participant_id}\")\n",
    "participant_dir = os.path.join(base_dir, \"assets\", choose_sub_dir, \"participants\" , f\"participant_{choose_participant_id}\")\n",
    " \n",
    "if os.path.exists(participant_dir):\n",
    "    participant_audio_fnames = [f for f in os.listdir(participant_dir) if f.endswith('.wav')]\n",
    "    os.makedirs(output_participant_dir, exist_ok=True)\n",
    "else:\n",
    "    raise ValueError(f\"Participant directory does not exist. Choose another participant id.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert wav and extract stim_info per participant id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stim_pairs = []\n",
    "for audio_fname in participant_audio_fnames:\n",
    "    audio_basename = audio_fname.strip(\".wav\")\n",
    "    parts = audio_fname.split(\"__\")\n",
    "    # node_id  = int(parts[0].split(\"_\")[1])\n",
    "    trial_id = int(parts[1].split(\"_\")[1])\n",
    "    \n",
    "    audio_path = os.path.join(participant_dir, audio_fname)\n",
    "    \n",
    "    audio_stim_tup = (audio_basename, audio_fname, f\"{audio_basename}_stim_info.json\") \n",
    "    audio_stim_pairs.append(audio_stim_tup)\n",
    "\n",
    "    ###########  Convert and save WAV file\n",
    "    data, fs = sf.read(audio_path)\n",
    "    # Convert to mono if stereo\n",
    "    if len(data.shape) == 2:\n",
    "        data = np.mean(data, axis=1)\n",
    "   \n",
    "    if fs != 44100:\n",
    "        data = librosa.resample(data, orig_sr=fs, target_sr=44100)\n",
    "        fs = 44100\n",
    "        \n",
    "    output_audio_path = os.path.join(output_participant_dir, audio_fname)\n",
    "    if not os.path.exists(output_audio_path):\n",
    "        sf.write(output_audio_path, data, fs, subtype='PCM_16')\n",
    "        print(f\"WAV converted and saved to {output_participant_dir}\")\n",
    "\n",
    "   \n",
    "    ###########  Stims info from CSV\n",
    "    stim_info = load_stim_info_from_csv(trial_id, TapTrialMusic_df)\n",
    "\n",
    "    # save stim_info to json\n",
    "    stim_info_json_path = os.path.join(output_participant_dir, f\"{audio_basename}_stim_info.json\")\n",
    "    \n",
    "    if not os.path.exists(stim_info_json_path):\n",
    "        with open(stim_info_json_path, 'w') as f:\n",
    "            json.dump(stim_info, f, indent=4)\n",
    "        print(\"stim_info saved:\", stim_info)\n",
    "  \n",
    "participant_stim_info_fnames = [f for f in os.listdir(output_participant_dir) if f.endswith('.json')]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repp Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Beat Finding Analysis\n",
    "# import repp_beatfinding.beat_detection as beat_detection\n",
    "# reload(beat_detection)\n",
    "\n",
    "\n",
    "# from repp.config import sms_tapping\n",
    "\n",
    "long_tapping= ConfigUpdater.create_config(\n",
    "    sms_tapping,\n",
    "    {\n",
    "        'EXTRACT_THRESH': [0.19, 0.2],\n",
    "        'EXTRACT_COMPRESS_FACTOR': 1,\n",
    "        'EXTRACT_FIRST_WINDOW': [18, 18],\n",
    "        'EXTRACT_SECOND_WINDOW': [26, 60],\n",
    "        ## TODO: add a parameter that extend the MARKER ERROR THRESHOLD to 20.\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "for recording_basename, recording_fname, stim_info_fname in audio_stim_pairs:\n",
    "\n",
    "    # Define filenames for outputs\n",
    "    filenames = {\n",
    "        'stim_info_file': stim_info_fname,\n",
    "        'audio_filename': 'stim_audio.wav',\n",
    "        'recording_filename': recording_fname,\n",
    "        'plot_filename': f'{recording_basename}.png',\n",
    "        'title_plot': 'Beat Finding Analysis'\n",
    "    }\n",
    "\n",
    "\n",
    "    with open(os.path.join(output_participant_dir, filenames['stim_info_file']), 'r') as f:\n",
    "        stim_info = json.load(f)\n",
    "    print(\"-------------------------------------------------\\n Running REPP\\n\")\n",
    "\n",
    "    output, extracted_onsets, stats = do_beat_detection_analysis(\n",
    "        os.path.join(output_participant_dir, filenames['recording_filename']),\n",
    "        filenames['title_plot'],\n",
    "        os.path.join(output_participant_dir, filenames['plot_filename']),\n",
    "        stim_info=stim_info, config=long_tapping\n",
    "    )\n",
    "    print(\"extracted onsets:-----------------------------\\n\")\n",
    "    print(extracted_onsets)\n",
    "    # and show the plot here\n",
    "    print(\"-------------------------------------------------\\n\")\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(14, 12))  # Adjust these numbers as needed\n",
    "    img = mpimg.imread(os.path.join(output_participant_dir, filenames['plot_filename']))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
